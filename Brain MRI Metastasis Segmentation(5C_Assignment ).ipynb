{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "U6AUOk-AyvVF",
        "outputId": "e023e85f-8ed5-4416-d399-f41ff0afbbba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, filters\n",
        "from skimage.exposure import equalize_adapthist"
      ],
      "metadata": {
        "id": "06JHSN3XyB4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# edit the location based on your dataset location\n",
        "image_dir = os.path.join('/content/drive/MyDrive/brain_mri_dataset', 'images')\n",
        "mask_dir = os.path.join('/content/drive/MyDrive/brain_mri_dataset', 'masks')\n",
        "\n",
        "image_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.nii.gz')]\n",
        "mask_files = [os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith('.nii.gz')]\n",
        "\n",
        "images = [io.imread(f, plugin='nibabel') for f in image_files]\n",
        "masks = [io.imread(f, plugin='nibabel') for f in mask_files]"
      ],
      "metadata": {
        "id": "gNZYsT1Q16yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clahe_images = []\n",
        "for image in images:\n",
        "    clahe_image = equalize_adapthist(image, clip_limit=0.03)\n",
        "    clahe_images.append(clahe_image)"
      ],
      "metadata": {
        "id": "mckApQEKyBzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clahe_images = [image / image.max() for image in clahe_images]"
      ],
      "metadata": {
        "id": "WSNyuXjpyBv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_images, val_images, train_masks, val_masks = train_test_split(clahe_images, masks, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "O2WVEyFByBst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def attention_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    attention_block = AttentionBlock(conv5, conv4)\n",
        "    up6 = concatenate([UpSampling2D(size=(2, 2))(attention_block), conv4], axis=3)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=3)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv7)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "class AttentionBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, input_shape):\n",
        "        super(AttentionBlock, self).__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.conv1 = Conv2D(64, (1, 1), activation='relu')\n",
        "        self.conv2 = Conv2D(64, (1, 1), activation='relu')\n",
        "        self.conv3 = Conv2D(1, (1, 1), activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.conv2(x)\n",
        "        attention_weights = self.conv3(x)\n",
        "        return attention_weights * inputs"
      ],
      "metadata": {
        "id": "VBTK5RoQyBpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nested_unet_model = nested_unet(input_shape=(256, 256, 1))\n",
        "attention_unet_model = attention_unet(input_shape=(256, 256, 1))\n",
        "\n",
        "nested_unet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "attention_unet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "LVQUTVUcyBly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nested_unet_history = nested_unet_model.fit(train_images, train_masks, epochs=10, batch_size=32, validation_data=(val_images, val_masks))\n",
        "attention_unet_history = attention_unet_model.fit(train_images, train_masks, epochs=10, batch_size=32, validation_data=(val_images, val_masks))"
      ],
      "metadata": {
        "id": "b6fCTylOyBip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nested_unet_loss, nested_unet_acc = nested_unet_model.evaluate(val_images, val_masks)\n",
        "attention_unet_loss, attention_unet_acc = attention_unet_model.evaluate(val_images, val_masks)\n",
        "\n",
        "print(f'Nested U-Net Loss: {nested_unet_loss:.4f}, Accuracy: {nested_unet_acc:.4f}')\n",
        "print(f'Attention U-Net Loss: {attention_unet_loss:.4f}, Accuracy: {attention_unet_acc:.4f}')"
      ],
      "metadata": {
        "id": "ORyU1fIdyBfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, File, UploadFile\n",
        "from fastapi.responses import HTMLResponse\n",
        "from fastapi.staticfiles import StaticFiles\n",
        "from fastapi.templating import Jinja2Templates\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "templates = Jinja2Templates(directory=\"templates\")\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "async def predict(file: UploadFile = File(...)):\n",
        "    image = Image.open(file.file)\n",
        "    image = image.resize((256, 256))\n",
        "    image = np.array(image) / 255.0\n",
        "    image = image.reshape((1, 256, 256, 1))\n",
        "\n",
        "    model = tf.keras.models.load_model('best_model.h5')\n",
        "    prediction = model.predict(image)\n",
        "\n",
        "    return {\"prediction\": prediction}"
      ],
      "metadata": {
        "id": "9wpRssQAyBcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "st.title(\"Brain MRI Metastasis Segmentation\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload Brain MRI Image\", type=[\"nii.gz\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = np.array(Image.open(uploaded_file))\n",
        "    image = image.resize((256, 256))\n",
        "    image = image / 255.0\n",
        "    image = image.reshape((1, 256, 256, 1))\n",
        "\n",
        "    model = tf.keras.models.load_model('best_model.h5')\n",
        "    prediction = model.predict(image)\n",
        "\n",
        "    st.write(\"Prediction:\")\n",
        "    plt.imshow(prediction[0, :, :, 0], cmap='gray')\n",
        "    st.pyplot(plt)"
      ],
      "metadata": {
        "id": "DmuzH09ayBYi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}